
In accordance with the requests in the take home email, this is a READ ME talking about the project and what I did.

Initially, I was excited about this problem as I have some issues with my email in that I get way more than I care to. I dont consider it all spam but I do spend a lot of time deleting things that I dont even read. In an effort to get the most out of this I decided to use a non-professional email, that way there is a lot of spam and nonsense to use - or so I thought. 
There were a lot of issue in getting GMAIL API to work properly as there is just not enough documentation for it. Once I did get it working I decided to build it into a simple class for calling to make things easier. I applied various filter as to which "labels" to use to make sure I didnt get a bunch of self emails or chats from friends. Once that as a complete I ended up with about ~1800 emails but not all unique. There were additional issues with declaring empty variables so default values from prior email fetches didnt sit in the environment.
What I learned from my emails is that they really arent that interesting - hah! I assumed there would be many emails related to various subscriptions I have such as medium and data science but the reality is, it was the same thing that I already deal with - a ton of political emails. One of my biggest gripes with these is that lets say I want to sign a petition, thats fine but then when I do that I am usually "subscribed" to an email list and often without the ability to opt out, so then all of a sudden I get many many emails asking for donations. This is where my work took a turn as I decided I wanted to try and examine if I can tell these emails apart - petition vs donation. After using some standard NLP analysis tools such as word clouds and word frequency charts, I moved into some unsupervised topic modeling to try and see if I could get any more details and potentially create an automatic labeling device. This didnt pan out. It was apparent that in all of the emails I pulled down there was VERY similar vocab across the whole population and thus none of the topic modeling approaches really took any good shape.
In the end, I decided to perform a simple and manual labeling of the emails for those that might be petition and those that might be donation and those that are both. My manual labeling was based on keywords such as donate, donation, sign, petition, action etc. The target was very imbalanced and I decided to drop the 3 instances that were labeled as both donation and petition. Despite being imblanced, I used an 8 fold KFold cross validation with a simple random forest with 500 estimators at a depth of 7. I figured that performing a grid search might be a little over kill for the small data set. As for features, I initially began with both TFIDF and COUNT vectorization methods but the model was over fitting and I decided to simply down to 100 TFIDF features. The model performed better than expected but I think it comes back to the way the data was manually labeled as visual examination of the test set highlighted that manhy of the emails, although "correctly" classified could go either way for petition or donation. Using SHAP I found that words such as DONATE, ACTION, SIGN, VIEW etc. were just common through both sets of email keywords.
WIth the exception of the headache of that GMAIL API, I had a fun time working through this project. Like most things, there are places I could have spent more time and probably given more effort but as I dont perform NLP work on a daily basis, I think this is fair start.

The structure of this repo:
- dev : folder with dev notebooks
- data : folder with data
- Way2B1_v2.ipynb : notebook containing the relevant work
- README.txt
- quickstart.py : the GMAIL API suggested py file
- MyGmailAPI.py : the gmail api class for pulling in emails
- requirements.txt : an output from my environment
- token.json : GMAIL api token
- credentials.json : GMAIL credentials